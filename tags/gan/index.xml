<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gan on PPT Developers&#39; Blog</title>
    <link>https://persol-pt.github.io/tags/gan/</link>
    <description>Recent content in Gan on PPT Developers&#39; Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Fri, 02 Nov 2018 11:21:51 +0900</lastBuildDate>
    
	<atom:link href="https://persol-pt.github.io/tags/gan/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>勉強会[GAN ～ガンだったりギャンだったり～]</title>
      <link>https://persol-pt.github.io/posts/tech-workshop_gan/</link>
      <pubDate>Fri, 02 Nov 2018 11:21:51 +0900</pubDate>
      
      <guid>https://persol-pt.github.io/posts/tech-workshop_gan/</guid>
      <description>皆さんこんにちは。
パーソルプロセス＆テクノロジー株式会社のyoshi-satoです。
今週もテクテクの勉強会の様子をお送りいたします。
よろしくお願いします。
※技術的なブログについてはQiitaでメンバーが各々に書き進めています。
こちらもぜひご覧ください。
Qiita - パーソルプロセス&amp;amp;テクノロジー
今週の発表者は、AI分野に詳しいテクテク部の桑田さんです。
テーマは「GAN ～ガンだったりギャンだったり～」でした。  
テーマ「GAN ～ガンだったりギャンだったり～」 GAN(Generative Adversarial Network)とは、ディープラーニングの仕組みで画像を生成するモデルです。
私自身AI系の技術には触れたことがなく、GANも今回の桑田さんの発表で初めて知った概念なので、追いかけるのが大変でした。
pix2pix はじめにGANを利用したアルゴリズムを紹介して頂きました。
一つ目は、pix2pixと呼ばれるもので、2つの画像のペア、たとえば白黒画像とカラー画像や、
線画と写真などを学習させると、自動的に画像の類似点を学習し、白黒画像→カラー画像や線画→写真など
任意の画像を変換した画像を生成することが出来るというものです。　 線画を猫のカラー画像に変換するデモページもあるそうですが、
 使い方を誤ると未来永劫拭い去ることの出来ないトラウマを植えつけられることになります。
vid2vid vid2vidは、上のpix2pixの動画版のようなもので、静止画ではなく動画を変換することが出来ます。
下の例のように、左のカラフルな人形が踊っている動画から、右の女性が踊っている動画に変換することが出来ます。
影まで付いていてリアルです。しかも動きます。
夢しかない。
 
GANって何？ ではGANとはいったいなんでしょう？
GANとは、データの分類を行う識別モデルとは異なり、データを生成する生成モデルと呼ばれるものの一種です。
Generative Adversarial Network（敵対生成ネットワーク）の名のとおり、敵対する2つのモデルを用いて学習を行います。
generatorと呼ばれるモデルと、discriminatorと呼ばれるモデルの2つに分かれており、generatorが乱数を元に生成した偽物の画像と、本物の画像をdiscriminatorに渡し、discriminatorがその画像が本物か偽物かを判断します。
これを繰り返して学習を行い、discriminatorが真贋判断できない画像を生成することがゴールとなります。
学習が成功すれば他の手法よりも鮮明な画像が生成できる一方、2つのモデルのうち片方だけが強くなってしまうなど
学習が不安定で、上手く学習させるためにはテクニックが必要になるそうです。
また、学習にコスト・時間がかかるというデメリットもあります。
NVIDIA Tesla V100を8機搭載しているDGX-1という機器（約1400万円!）の使用が推奨されており、それでも学習に数日かかることもあるそうです。
 
「ふと」 GANについての説明をして頂いたので、次にくるのは十中八九「GANやってみた」的なスライドだと会議室の誰もが思ったでしょう(たぶん) 。
 「GANを利用しない場合どういった結果になるのか」
GANを語った上で、GANを使わないという私のような素人の目には暴挙とも映る検証を行います。
 検証内容としては、GANを使ってアニメ「キルミーベイベー」のキャラクターを生成する記事を、GANを使用しない3つの方法で再現するという内容です。
方法① 逆畳み込み 大きなイメージから特徴を抽出しつつ小さなイメージに縮小していく畳み込みと呼ばれるアルゴリズムとは逆に、
小さなイメージを拡大してから畳み込むという方式です。
 方法② 単純パーセプトロン 入力に対して重み付けを行い、それらの合計が閾値を超えるか超えないかを判断するアルゴリズムです。</description>
    </item>
    
  </channel>
</rss>