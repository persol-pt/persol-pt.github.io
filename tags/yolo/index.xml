<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yolo on PPT Developers&#39; Blog</title>
    <link>https://persol-pt.github.io/tags/yolo/</link>
    <description>Recent content in Yolo on PPT Developers&#39; Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 09 May 2018 14:49:20 +0900</lastBuildDate>
    
	<atom:link href="https://persol-pt.github.io/tags/yolo/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>勉強会[物体検出アルゴリズム YOLO]</title>
      <link>https://persol-pt.github.io/posts/tech-workshop20180420/</link>
      <pubDate>Wed, 09 May 2018 14:49:20 +0900</pubDate>
      
      <guid>https://persol-pt.github.io/posts/tech-workshop20180420/</guid>
      <description>みなさんこんにちは、
パーソルプロセスアンドテクノロジー株式会社のEP統括部、daitasuです。
今週も私たちの部の勉強会の様子をお送りいたします。
※技術的なブログについてはQiitaでメンバーが各々に書き進めています。
こちらもぜひご覧ください。
Qiita - パーソルプロセス&amp;amp;テクノロジー
さて、今週の発表者は私の直属のMGRであります、川崎さんのプレゼンです。
テーマは「YOLOってみた」です。
テーマ「YOLOってみた」   
みなさん、YOLOってご存知でしょうか？
私は今回初めて知ったのですが、YOLOというのは、
&amp;lsquo;You only look once&amp;rsquo;、
リアルタイムに画像認識を行い、物体を検出するアルゴリズムを指します。
川崎さんは、今回自宅の動画を撮影し、このYOLOを利用して、
物体検出がどのくらいの制度か、どのくらいの変換速度なのかを検証したお話を
してくださいました。
そもそもYOLOってどんなもの？ 
  
上記のように、YOLOはDarknetというフレームワークを用いて
画像/動画からオブジェクトを検出しています。
そして、そのオブジェクトが何なのか(人なのか、車なのか、植物なのか等)を
判断し、分類をリアルタイムに行っています。
実際の画像を見てみましょう！
  
「Person」と「laptop」が検出されていますね。
このように、画像/動画から物体検出し、分類した結果を枠で囲い伝えてくれます。
川崎さんが撮影した自宅の動画では、人や植物、机、TVなど
想像以上に細かに分類がなされていました。
以下のサイトなどを見て頂けると、
YOLOの面白さが伝わるのではないかと思います。
YOLO動画 検証環境 
  検証した環境     用意するもの   
YOLOはCPU単体だと非常に動きが悪くなるようで、GPUを積んだマシンで行う必要があります
今回の検証では、CPU単体での処理と、
GPUを利用した場合の2種類のプログラムで検証しています。
検証結果   検証結果   CPU単体だと速度が全く出ず、
動画でもすごく遅いGIF画像を見ているような動きになっていました。</description>
    </item>
    
  </channel>
</rss>